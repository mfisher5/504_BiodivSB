---
title: "Q1 Random Forest"
author: "Mary Fisher"
date: "3/14/2020"
output: html_document
---
#### Research Question: Which oceanographic and herbivory conditions are important for predicting giant kelp size and abundance?

**Response variables:** Giant kelp mean abundance, max abundance; Giant kelp mean size, maximum size. 

**Predictor variables: **

1. Urchin abundance: Sea urchins are herbivores, and in large numbers (also called "herds") can decimate kelp forests. We have three measures of urchin abundance - red urchin abundance, purple urchin abundance, and urchin abundance across all species.

2. Water chemistry: Like any algae / plant, kelp requires nutrients to grow. We have measurements for the following nutrients: nitrogen, ammonia, urea, and phosphorus. We also have chlorophyl concentrations, which is a general index of primary productivity.

3. Water temperature: All species have a thermal range, or a range of temperatures, at which they grow best; the degree of variability in temperature can also have an impact on growth. With kelp forest loss from recent marine heatwaves and long-term warming, there has been much interest in whether kelp are impacted by an absolute temperature threshold, or by the degree of variability in temperature. We have mean summer and mean winter temperatures, and variation in summer and mean winter temperatures. 

4. Giant kelp mean / max abundance, mean / max size at t-1: This data set is a time series, so the giant kelp response variable at a given site for year `t` should be dependent on giant kelp condition in year `t-1`.



**Modeling approach:** Random Forest analysis incorporating previous size / abundance.



```{r setup, include=FALSE}
rm(list=ls())

knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(janitor)
library(here)
library(vegan)
library(lubridate)
library(corrplot)
library(MASS)
library(performance)

```
<br>

# Prepare Data

Read in data
```{r echo=TRUE}
mydat <- read.csv(here::here("data","kelp_prediction_data_complete.csv")) %>%
  clean_names()
head(mydat)
```
<br>

Add in the giant kelp response variables for `t-1`.
```{r}
# need kelp info from 2001
kelp_dat <- read.csv(here::here("data","Annual_Kelp_MeanSize_MeanAbund_2001-2018.csv")) %>%
  clean_names() %>%
  filter(site %in% mydat$site & year == 2001) %>%
  dplyr::select(-month) %>%
  rename("prev_mean_density" = mapy_mean_density,
         "prev_mean_count"=mapy_mean_count,
         "prev_mean_fronds"=mapy_mean_fronds,
         "prev_max_fronds"=mapy_max_fronds,
         "prev_mean_hld"=mapy_mean_hld,"prev_max_hld"=mapy_max_hld) %>%
  mutate(year = year + 1)
kelp_prev <- read.csv(here::here("data","kelp_prediction_data.csv")) %>%
  clean_names() %>%
  dplyr::select(year,month,site,mapy_mean_density,mapy_mean_count,mapy_mean_fronds,mapy_max_fronds,mapy_mean_hld,mapy_max_hld) %>%
  rename("prev_mean_density" = mapy_mean_density,
         "prev_mean_count"=mapy_mean_count,
         "prev_mean_fronds"=mapy_mean_fronds,
         "prev_max_fronds"=mapy_max_fronds,
         "prev_mean_hld"=mapy_mean_hld,"prev_max_hld"=mapy_max_hld) %>%
  mutate(year = year + 1) %>%
  dplyr::select(-month) %>%
  rbind(kelp_dat)
mydat <- left_join(mydat,kelp_prev,by=c("year","site"))

message("\nThere are ", sum(is.na(mydat$prev_mean_density)), " missing measurements for the previous year's kelp abundance.\n")

colnames(mydat)
```
<br>


## Predictor Variable Selection

We have three variables that quantify urchin abundance - we'll just work with total abundance (`urchin_abundance`). This variable is zero-inflated, a common problem with ecological count data. So I'm going to split it into two predictor variables - a categorical presence / absence variable, and then an abundance variable. The abundance variable will have a square-root transformation.


The maximum values of water chemistry estimates were very difficult to force into a normal distribution. So I'm only going to work with the mean values. 

Based on multicollinearity plots for the OLS / GLM regression, I need to get rid of (1) winter temperatures, and (2) particulate organic carbon (poc)

```{r echo=TRUE}
lmdat <- dplyr::select(mydat, -purpuratus_abundance,-franciscanus_abundance) %>%
  mutate(urchin_presence = ifelse(urchin_abundance > 0, 1, 0),
         urchin_abundance = ifelse(urchin_abundance==0,0,urchin_abundance)) %>%
  dplyr::select(-max_ammonia,-max_no2_no3,-max_po4,-max_poc,-max_pon,-max_tchl) %>%
  dplyr::select(-winter_mean_temp,-winter_var_temp) %>%
  dplyr::select(-mean_poc)
```
<br>

## Transform Variables

According to the script [04_explore_predictors](https://github.com/mfisher5/504_BiodivSB/tree/master/scripts), many of the predictor variables are not normally distributed. The abundance variable will need a square-root transformation.

Previous mean density and mean number of fronds need to be log-transformed. Maximum number of fronds and holdfast diameter need a square root transformation. 

```{r echo=TRUE}
lmdat.t <- lmdat %>%
  mutate(urchin_abundance = sqrt(urchin_abundance),
         summer_var_temp = log(summer_var_temp),
         mean_pon= log(mean_pon),
         mean_tchl= log(mean_tchl),
         prev_mean_density = log(prev_mean_density),
         prev_mean_count = log(prev_mean_count),
         prev_mean_fronds = log(prev_mean_fronds),
         prev_max_fronds = sqrt(prev_max_fronds),
         prev_max_hld = sqrt(prev_max_hld))
```
<br>
```{r}
par(mfrow=c(2,2))
hist(lmdat.t$urchin_abundance, main="")
hist(lmdat.t$mean_ammonia, main="")
hist(lmdat.t$mean_no2_no3, main="")
hist(lmdat.t$mean_po4, main="")
hist(lmdat.t$mean_pon, main="")
hist(lmdat.t$mean_tchl, main="")
hist(lmdat.t$summer_mean_temp, main="")
hist(lmdat.t$summer_var_temp, main="")

par(mfrow=c(2,3))
hist(lmdat.t$prev_mean_density,main="")
hist(lmdat.t$prev_mean_count,main="")
hist(lmdat.t$prev_mean_fronds,main="")
hist(lmdat.t$prev_max_fronds,main="")
hist(lmdat.t$prev_max_hld,main="")
```

Final data set:
```{r}
colnames(lmdat.t)
dim(lmdat.t)
```
<br>
<br>


---

# Random Forest

## Kelp Abundance

*Response:* log(`mapy_mean_density`)

The random forest to predict kelp abundance will use the following variables:
```{r}
abund_dat <- dplyr::select(lmdat.t, mapy_mean_density,site, urchin_presence, urchin_abundance, prev_mean_density, mean_ammonia, mean_no2_no3, mean_po4, mean_tchl, mean_pon, summer_mean_temp, summer_var_temp)

abund_dat$urchin_presence <- as.factor(abund_dat$urchin_presence)
abund_dat$site <- as.factor(abund_dat$site)

colnames(abund_dat)
```
<br>

Split the data into a training and a test data set
```{r echo=TRUE}
set.seed(100)
train <- sample(nrow(abund_dat), 0.7*nrow(abund_dat), replace = FALSE)
TrainSet <- abund_dat[train,] %>%
  mutate(mapy_mean_density = log(mapy_mean_density))
ValidSet <- abund_dat[-train,] %>%
  mutate(mapy_mean_density = log(mapy_mean_density))
summary(TrainSet)
summary(ValidSet)
```
<br>


### Tune Parameters

perform a larger grid search across several hyperparameters. 

First, create the grid of parameter combinations
```{r}
hyper_grid <- expand.grid(
  mtry       = seq(4, 30, by = 2),
  node_size  = seq(3, 9, by = 2),
  sampe_size = c(.55, .632, .70, .80),
  OOB_RMSE   = 0
)
```
<br>

"We loop through each hyperparameter combination and apply 500 trees since our previous examples illustrated that 500 was plenty to achieve a stable error rate. Also note that we set the random number generator seed. This allows us to consistently sample the same observations for each sample size and make it more clear the impact that each change makes. Our OOB RMSE ranges between ~26,000-27,000. Our top 10 performing models all have RMSE values right around 26,000 and the results show that models with slighly larger sample sizes (70-80%) and deeper trees (3-5 observations in an terminal node) perform best. We get a full range of mtry values showing up in our top 10 so is does not look like that is over influential."
```{r}
set.seed(100)

for(i in 1:nrow(hyper_grid)) {
  
  # train model
  model <- ranger(
    formula         = mapy_mean_density ~ ., 
    data            = TrainSet, 
    num.trees       = 500,
    mtry            = hyper_grid$mtry[i],
    min.node.size   = hyper_grid$node_size[i],
    sample.fraction = hyper_grid$sampe_size[i],
    seed            = 123
  )
  
  # add OOB error to grid
  hyper_grid$OOB_RMSE[i] <- sqrt(model$prediction.error)
}

hyper_grid %>% 
  dplyr::arrange(OOB_RMSE) %>%
  head(10)
```
<br>








